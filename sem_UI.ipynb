{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1oKMh9x013ZUZ6b924XTr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zia-Ul-Hasan/NLP_SEMACNTIC_PRODUCT_SEARCH/blob/main/sem_UI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEP0pONH3Yh0"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load model\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model = SentenceTransformer('D:/nlp______/saved_model')  # Load your saved model directory here\n",
        "    return model\n",
        "\n",
        "# Load data\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    # Load the cleaned merged CSV instead of old product.csv\n",
        "    product_df = pd.read_csv('D:/PROjects/nlp project/cleaned_merged_products.csv')  # <-- updated path\n",
        "    product_embeddings = np.load('D:/Opera_downloads/product_embeddings_full.npy')  # Make sure this matches cleaned CSV rows\n",
        "\n",
        "    # Verify embeddings length matches dataframe rows\n",
        "    if product_embeddings.shape[0] != len(product_df):\n",
        "        raise ValueError(\n",
        "            f\"Mismatch between embeddings ({product_embeddings.shape[0]}) and \"\n",
        "            f\"product dataframe rows ({len(product_df)})\"\n",
        "        )\n",
        "    return product_df, product_embeddings\n",
        "\n",
        "\n",
        "model = load_model()\n",
        "product_df, product_embeddings = load_data()\n",
        "\n",
        "# Text cleaning function consistent with preprocessing\n",
        "def clean_text(text):\n",
        "    return re.sub(r'[^a-z0-9\\s]', ' ', str(text).lower()).strip()\n",
        "\n",
        "# Search logic\n",
        "def get_top_matches(query, top_k=5):\n",
        "    query = clean_text(query)\n",
        "    query_vector = model.encode([query], normalize_embeddings=True)\n",
        "    similarities = np.dot(product_embeddings, query_vector.T).squeeze()\n",
        "\n",
        "    st.write(f\"Data rows: {len(product_df)}\")\n",
        "    st.write(f\"Embeddings shape: {product_embeddings.shape}\")\n",
        "    st.write(f\"Similarities shape: {similarities.shape}\")\n",
        "\n",
        "    actual_top_k = min(top_k, len(similarities))\n",
        "    top_indices = similarities.argsort()[-actual_top_k:][::-1]\n",
        "\n",
        "    return product_df.iloc[top_indices]\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"ðŸ”Ž Semantic Product Search\")\n",
        "\n",
        "query = st.text_input(\"Enter your product search query:\")\n",
        "\n",
        "if query:\n",
        "    results = get_top_matches(query)\n",
        "    st.subheader(\"Top Matches:\")\n",
        "    st.dataframe(results)\n"
      ]
    }
  ]
}